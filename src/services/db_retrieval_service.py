import os
import logging
import json
from typing import List, Dict
from sqlalchemy import select
from openai import AsyncOpenAI
from src.database.connection import AsyncSessionLocal
from src.database.models import Article

class DbRetrievalService:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    async def _llm_filter(self, topic: str, candidates: List[Article]) -> List[Dict]:
        """
        El LLM act√∫a como filtro sem√°ntico final sobre la lista de la misma categor√≠a.
        """
        if not candidates:
            return []

        # Preparamos texto ligero (ID + T√≠tulo)
        candidates_text = ""
        for i, art in enumerate(candidates):
            candidates_text += f"ID {i}: {art.title}\\n"

        prompt = f"""
        Eres un curador de contenidos experto.

        TEMA ESPEC√çFICO DEL USUARIO: "{topic}"

        Lista de noticias disponibles (Todas pertenecen a la misma categor√≠a general):
        {candidates_text}

        TAREA:
        Selecciona los IDs de las noticias que traten ESPEC√çFICAMENTE sobre "{topic}" o est√©n muy relacionadas.
        Si el tema es "Real Madrid", selecciona noticias del equipo, jugadores, partidos, etc. Ignora otros equipos.

        Responde solo JSON: {{ "selected_ids": [0, 2] }}
        """

        try:
            response = await self.client.chat.completions.create(
                model="gpt-5-nano",
                messages=[
                    {"role": "system", "content": "Responde solo JSON valid."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
            )

            data = json.loads(response.choices[0].message.content)
            indices = data.get("selected_ids", [])

            filtered = []
            for idx in indices:
                if 0 <= idx < len(candidates):
                    a = candidates[idx]
                    filtered.append({
                        "title": a.title,
                        "url": a.url,
                        "content": a.content,
                        "source": a.source_name,
                        "published_at": a.published_at
                    })

            self.logger.info(f"   ü§ñ LLM seleccion√≥ {len(filtered)} de {len(candidates)} noticias de la categor√≠a.")
            return filtered

        except Exception as e:
            self.logger.error(f"Error en filtro LLM: {e}")
            return []

    async def get_articles_for_topic(self, topic: str, category: str, limit: int = 50) -> List[Dict]:
        """
        1. Trae noticias de la DB que coincidan con la CATEGOR√çA.
        2. Pasa el filtro LLM para el TEMA.
        """
        self.logger.info(f"üîç Buscando noticias en DB | Categor√≠a: '{category}' | Tema: '{topic}'")

        async with AsyncSessionLocal() as session:
            # 1. CONSULTA SQL PURA (Escalable y R√°pida)
            # Ordenamos por fecha descendente (las m√°s nuevas primero)
            stmt = select(Article).where(
                Article.category == category
            ).order_by(Article.published_at.desc()).limit(limit)

            result = await session.execute(stmt)
            category_articles = result.scalars().all()

            if not category_articles:
                self.logger.warning(f"   ‚ö†Ô∏è No hay noticias en la DB para la categor√≠a '{category}'.")
                return []

            self.logger.info(f"   üì• Recuperadas {len(category_articles)} noticias recientes de '{category}'. Filtrando con IA...")

            # 2. FILTRADO INTELIGENTE
            return await self._llm_filter(topic, category_articles)
